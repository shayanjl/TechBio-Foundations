{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b71263",
   "metadata": {},
   "source": [
    "# Building the First Model\n",
    "## From Clean Data to First Predictions\n",
    "\n",
    "### 1. Introduction: The Pivot Point\n",
    "\n",
    "In **Notebook 1**, we cleaned a messy biological dataset. We standardized column names, handled missing values, and engineered features.\n",
    "\n",
    "In **Notebooks 2 and 3**, we looked at the bigger picture: automation and economics.\n",
    "\n",
    "Now, we return to the core science. We take the clean data from Step 1 and turn it into intelligence.\n",
    "\n",
    "This notebook demonstrates the **Modeling Step** of the TechBio loop:\n",
    "> Biology → Data → **Model** → Validation → Better Biology\n",
    "\n",
    "We will:\n",
    "1.  Load a clean, model-ready dataset (simulated for this exercise).\n",
    "2.  Define a clear biological prediction task.\n",
    "3.  Train a simple machine learning model.\n",
    "4.  Interpret what the model learned.\n",
    "\n",
    "The goal is not to build the world's best predictor, but to understand the *mechanics* of connecting data to insight.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Loading the Model-Ready Dataset\n",
    "\n",
    "In a real project, you would load the `.csv` file you saved in Notebook 1. Since we are in a new session, we will quickly regenerate a similar clean dataset here to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db59cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-ready dataset (first 5 rows):\n",
      "           Sample_B   Sample_C  GC_Content_Feature\n",
      "Gene_ID                                           \n",
      "GENE_001  11.986857  13.463790           66.302659\n",
      "GENE_002   9.446943   9.789679           39.971689\n",
      "GENE_003  12.590754  12.359458           46.415317\n",
      "GENE_004  16.092119  15.489912           60.222046\n",
      "GENE_005   9.063387   6.106343           39.151927\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- create a larger synthetic model-ready dataset ----\n",
    "np.random.seed(42)\n",
    "\n",
    "n_genes = 40\n",
    "\n",
    "# Make some fake gene IDs\n",
    "gene_ids = [f\"GENE_{i:03d}\" for i in range(1, n_genes + 1)]\n",
    "\n",
    "# Sample_B: base expression values\n",
    "sample_b = np.random.normal(loc=10.0, scale=4.0, size=n_genes)\n",
    "\n",
    "# Sample_C: correlated with Sample_B + some noise\n",
    "sample_c = sample_b + np.random.normal(loc=0.0, scale=2.0, size=n_genes)\n",
    "\n",
    "# GC_Content_Feature: %GC between 30 and 70\n",
    "gc_content = np.random.uniform(low=30.0, high=70.0, size=n_genes)\n",
    "\n",
    "model_ready_df = pd.DataFrame({\n",
    "    \"Gene_ID\": gene_ids,\n",
    "    \"Sample_B\": sample_b,\n",
    "    \"Sample_C\": sample_c,\n",
    "    \"GC_Content_Feature\": gc_content\n",
    "}).set_index(\"Gene_ID\")\n",
    "\n",
    "print(\"Model-ready dataset (first 5 rows):\")\n",
    "print(model_ready_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea6578",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Defining the Prediction Task\n",
    "\n",
    "A model needs a goal. In TechBio, this goal usually comes from a biological question.\n",
    "\n",
    "For this exercise, our question is:\n",
    "**\"Can we predict which genes will be highly expressed in Sample C, based only on their expression in Sample B and their GC content?\"**\n",
    "\n",
    "* **Features (Inputs):** `Sample_B` expression + `GC_Content_Feature`\n",
    "* **Target (Output):** A binary label (1 = High Expression, 0 = Low Expression)\n",
    "\n",
    "We define \"High Expression\" as anything above the median value in Sample C. This turns a complex biological phenomenon into a solvable classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46cb1951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_001  11.986857           66.302659\n",
      "GENE_002   9.446943           39.971689\n",
      "GENE_003  12.590754           46.415317\n",
      "GENE_004  16.092119           60.222046\n",
      "GENE_005   9.063387           39.151927\n",
      "GENE_006   9.063452           33.079196\n",
      "GENE_007  16.316851           41.590058\n",
      "GENE_008  13.069739           36.448851\n",
      "GENE_009   8.122102           67.187906\n",
      "GENE_010  12.170240           62.324815\n",
      "GENE_011   8.146329           55.336150\n",
      "GENE_012   8.137081           64.858424\n",
      "GENE_013  10.967849           62.146883\n",
      "GENE_014   2.346879           37.462802\n",
      "GENE_015   3.100329           65.702360\n",
      "GENE_016   7.750850           51.573690\n",
      "GENE_017   5.948676           62.297606\n",
      "GENE_018  11.256989           65.843652\n",
      "GENE_019   6.367904           42.720139\n",
      "GENE_020   4.350785           34.402077\n",
      "GENE_021  15.862595           39.117407\n",
      "GENE_022   9.096895           47.084312\n",
      "GENE_023  10.270113           62.720591\n",
      "GENE_024   4.301007           64.429223\n",
      "GENE_025   7.822469           30.278085\n",
      "GENE_026  10.443690           50.429892\n",
      "GENE_027   5.396026           46.696440\n",
      "GENE_028  11.502792           38.884312\n",
      "GENE_029   7.597445           34.794615\n",
      "GENE_030   8.833225           43.504607\n",
      "GENE_031   7.593174           67.716388\n",
      "GENE_032  17.409113           42.928117\n",
      "GENE_033   9.946011           50.751625\n",
      "GENE_034   5.769156           58.120758\n",
      "GENE_035  13.290180           44.545184\n",
      "GENE_036   5.116625           68.871283\n",
      "GENE_037  10.835454           68.497892\n",
      "GENE_038   2.161320           40.071292\n",
      "GENE_039   4.687256           49.889940\n",
      "GENE_040  10.787445           42.035132\n",
      "\n",
      "Target (y):\n",
      "Gene_ID\n",
      "GENE_001    1\n",
      "GENE_002    1\n",
      "GENE_003    1\n",
      "GENE_004    1\n",
      "GENE_005    0\n",
      "GENE_006    0\n",
      "GENE_007    1\n",
      "GENE_008    1\n",
      "GENE_009    1\n",
      "GENE_010    0\n",
      "GENE_011    1\n",
      "GENE_012    0\n",
      "GENE_013    1\n",
      "GENE_014    0\n",
      "GENE_015    0\n",
      "GENE_016    1\n",
      "GENE_017    0\n",
      "GENE_018    1\n",
      "GENE_019    0\n",
      "GENE_020    0\n",
      "GENE_021    1\n",
      "GENE_022    1\n",
      "GENE_023    0\n",
      "GENE_024    0\n",
      "GENE_025    1\n",
      "GENE_026    1\n",
      "GENE_027    0\n",
      "GENE_028    1\n",
      "GENE_029    0\n",
      "GENE_030    0\n",
      "GENE_031    0\n",
      "GENE_032    1\n",
      "GENE_033    1\n",
      "GENE_034    1\n",
      "GENE_035    0\n",
      "GENE_036    0\n",
      "GENE_037    1\n",
      "GENE_038    0\n",
      "GENE_039    0\n",
      "GENE_040    0\n",
      "Name: Sample_C, dtype: int64\n",
      "\n",
      "Median of Sample_C: 8.684868354172306\n"
     ]
    }
   ],
   "source": [
    "# Features: what the model will see\n",
    "X = model_ready_df[[\"Sample_B\", \"GC_Content_Feature\"]]\n",
    "\n",
    "# Target: high vs low expression in Sample_C\n",
    "median_sample_c = model_ready_df[\"Sample_C\"].median()\n",
    "y = (model_ready_df[\"Sample_C\"] >= median_sample_c).astype(int)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X)\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y)\n",
    "print(f\"\\nMedian of Sample_C: {median_sample_c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abe100",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. The Virtual Experiment: Splitting the Data\n",
    "\n",
    "In TechBio, we never train on all our data. We always hold some back. This is called the **Test Set**.\n",
    "\n",
    "Why? Because biology is noisy. A model might memorize the noise in your training data (overfitting) but fail completely when you try it on a new patient sample or a new cell line.\n",
    "\n",
    "The **Test Set** acts like a \"blind validation study.\" The model never sees these genes during training. We only show them to the model *after* it is finished, to see if it actually learned the biology or just memorized the answers.\n",
    "\n",
    "We will split our 40 genes:\n",
    "* **Training Set (20 genes):** Used to teach the model.\n",
    "* **Test Set (20 genes):** Used to judge the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5f481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features:\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_006   9.063452           33.079196\n",
      "GENE_012   8.137081           64.858424\n",
      "GENE_002   9.446943           39.971689\n",
      "GENE_030   8.833225           43.504607\n",
      "GENE_022   9.096895           47.084312\n",
      "GENE_003  12.590754           46.415317\n",
      "GENE_031   7.593174           67.716388\n",
      "GENE_037  10.835454           68.497892\n",
      "GENE_004  16.092119           60.222046\n",
      "GENE_036   5.116625           68.871283\n",
      "GENE_024   4.301007           64.429223\n",
      "GENE_033   9.946011           50.751625\n",
      "GENE_011   8.146329           55.336150\n",
      "GENE_023  10.270113           62.720591\n",
      "GENE_019   6.367904           42.720139\n",
      "GENE_021  15.862595           39.117407\n",
      "GENE_008  13.069739           36.448851\n",
      "GENE_015   3.100329           65.702360\n",
      "GENE_029   7.597445           34.794615\n",
      "GENE_039   4.687256           49.889940\n",
      "\n",
      "Training labels:\n",
      "Gene_ID\n",
      "GENE_006    0\n",
      "GENE_012    0\n",
      "GENE_002    1\n",
      "GENE_030    0\n",
      "GENE_022    1\n",
      "GENE_003    1\n",
      "GENE_031    0\n",
      "GENE_037    1\n",
      "GENE_004    1\n",
      "GENE_036    0\n",
      "GENE_024    0\n",
      "GENE_033    1\n",
      "GENE_011    1\n",
      "GENE_023    0\n",
      "GENE_019    0\n",
      "GENE_021    1\n",
      "GENE_008    1\n",
      "GENE_015    0\n",
      "GENE_029    0\n",
      "GENE_039    0\n",
      "Name: Sample_C, dtype: int64\n",
      "\n",
      "Test features:\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_020   4.350785           34.402077\n",
      "GENE_017   5.948676           62.297606\n",
      "GENE_016   7.750850           51.573690\n",
      "GENE_027   5.396026           46.696440\n",
      "GENE_005   9.063387           39.151927\n",
      "GENE_013  10.967849           62.146883\n",
      "GENE_038   2.161320           40.071292\n",
      "GENE_028  11.502792           38.884312\n",
      "GENE_040  10.787445           42.035132\n",
      "GENE_007  16.316851           41.590058\n",
      "GENE_026  10.443690           50.429892\n",
      "GENE_010  12.170240           62.324815\n",
      "GENE_014   2.346879           37.462802\n",
      "GENE_032  17.409113           42.928117\n",
      "GENE_035  13.290180           44.545184\n",
      "GENE_009   8.122102           67.187906\n",
      "GENE_018  11.256989           65.843652\n",
      "GENE_025   7.822469           30.278085\n",
      "GENE_001  11.986857           66.302659\n",
      "GENE_034   5.769156           58.120758\n",
      "\n",
      "Test labels:\n",
      "Gene_ID\n",
      "GENE_020    0\n",
      "GENE_017    0\n",
      "GENE_016    1\n",
      "GENE_027    0\n",
      "GENE_005    0\n",
      "GENE_013    1\n",
      "GENE_038    0\n",
      "GENE_028    1\n",
      "GENE_040    0\n",
      "GENE_007    1\n",
      "GENE_026    1\n",
      "GENE_010    0\n",
      "GENE_014    0\n",
      "GENE_032    1\n",
      "GENE_035    0\n",
      "GENE_009    1\n",
      "GENE_018    1\n",
      "GENE_025    1\n",
      "GENE_001    1\n",
      "GENE_034    1\n",
      "Name: Sample_C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,   # half of the genes for testing, just for demonstration\n",
    "    random_state=42  # fixed seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Training features:\")\n",
    "print(X_train)\n",
    "print(\"\\nTraining labels:\")\n",
    "print(y_train)\n",
    "print(\"\\nTest features:\")\n",
    "print(X_test)\n",
    "print(\"\\nTest labels:\")\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c3152",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Training the Model\n",
    "\n",
    "Now we build the engine. We will use a **Random Forest Classifier**.\n",
    "\n",
    "Think of a Random Forest like a committee of scientists. It creates many small \"decision trees.\" Each tree looks at a random subset of the data and votes on whether a gene should be high or low expression. The forest counts the votes to make a final prediction.\n",
    "\n",
    "This is a \"workhorse\" algorithm in bioinformatics because:\n",
    "1.  It handles noisy biological data well.\n",
    "2.  It doesn't assume biology is linear (biological systems rarely are).\n",
    "3.  It tells us *which* features were important (we'll see this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f41a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,      # number of trees in the forest\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train (fit) the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a73fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. The Moment of Truth: Evaluation\n",
    "\n",
    "Now we run our \"virtual experiment.\"\n",
    "\n",
    "We take the 20 genes in our **Test Set** (which the model has never seen) and ask the model to predict their expression. Then, we compare those predictions to the actual lab results (`y_test`).\n",
    "\n",
    "**How to read the results:**\n",
    "* **50% Accuracy:** The model is guessing (random coin flip). The data might be too noisy, or the features don't matter.\n",
    "* **100% Accuracy:** Suspicious. Usually means \"data leakage\" (the answer was hidden in the question).\n",
    "* **60-80% Accuracy:** Typical for early biological models. It found a signal, but biology is messy.\n",
    "\n",
    "Let's see how our simple model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c807e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels:      [np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
      "Predicted labels: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
      "\n",
      "Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"True labels:     \", list(y_test.values))\n",
    "print(\"Predicted labels:\", list(y_pred))\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec986f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Opening the Black Box\n",
    "\n",
    "Accuracy scores are useful, but they don't tell you *biology*. To understand the science, you need to know **why** the model made its decisions.\n",
    "\n",
    "We will look at **Feature Importance**. This tells us which input variable (Sample B or GC Content) was more useful for making predictions.\n",
    "\n",
    "In a real discovery platform, this is how you find new biomarkers. If a model tells you that a specific gene feature is 90% responsible for drug resistance, you have just found a new hypothesis to test in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a9fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "              Feature  Importance\n",
      "0            Sample_B    0.690982\n",
      "1  GC_Content_Feature    0.309018\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance values\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6c6e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8. Bringing It All Together\n",
    "\n",
    "You have now completed the first half of the TechBio loop. You moved from **Data** to **Model** to **Insight**.\n",
    "\n",
    "1.  **Data:** You started with a clean, numerical table.\n",
    "2.  **Model:** You trained a Random Forest to find patterns.\n",
    "3.  **Insight:** You discovered which features drive the biological response.\n",
    "\n",
    "In a traditional lab, this insight would be the end of the project. You would write a paper and stop.\n",
    "\n",
    "In a TechBio company, this is just the beginning. The model's predictions are now used to design the **next** experiment.\n",
    "\n",
    "**What's Next?**\n",
    "In **Notebook 5 (TechBio Learning Loop)**, we will close the cycle. We will use a model like this one to *choose* the next set of experiments, generating new data that makes the model even smarter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
