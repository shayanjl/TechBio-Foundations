{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b71263",
   "metadata": {},
   "source": [
    "# Building the First Model  \n",
    "From Clean Data to First Predictions\n",
    "\n",
    "In the previous notebook, we took a messy gene-expression table and transformed it into **clean, structured, model-ready data**. We:\n",
    "\n",
    "- cleaned and standardized column names  \n",
    "- removed unreliable sample columns  \n",
    "- handled missing values safely  \n",
    "- filtered out corrupted sequences  \n",
    "- engineered a new feature, **GC_Content_Feature**, from the DNA sequences  \n",
    "\n",
    "By the end, we had a tidy table with numerical values that a machine learning model can understand.  \n",
    "Each row represented a gene, and each column represented a clean, validated feature.\n",
    "\n",
    "In this notebook, we take the **next step in the TechBio workflow**:  \n",
    "we use that clean dataset to train our **first simple machine learning model**.\n",
    "\n",
    "The purpose here is not to chase perfect accuracy.  \n",
    "The purpose is to show how modeling fits inside the larger TechBio loop:\n",
    "\n",
    "> Biology → Data → Cleaning → **Model** → Validation → Better Biology\n",
    "\n",
    "This notebook demonstrates that transition: clean data becoming an initial predictive model.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Loading the Model-Ready Dataset\n",
    "\n",
    "In a real project, you would export the cleaned table from the previous notebook and load it here, for example:\n",
    "\n",
    "```python\n",
    "model_ready_df = pd.read_csv(\"model_ready_dataset.csv\", index_col=\"Gene_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db59cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-ready dataset (first 5 rows):\n",
      "           Sample_B   Sample_C  GC_Content_Feature\n",
      "Gene_ID                                           \n",
      "GENE_001  11.986857  13.463790           66.302659\n",
      "GENE_002   9.446943   9.789679           39.971689\n",
      "GENE_003  12.590754  12.359458           46.415317\n",
      "GENE_004  16.092119  15.489912           60.222046\n",
      "GENE_005   9.063387   6.106343           39.151927\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- create a larger synthetic model-ready dataset ----\n",
    "np.random.seed(42)\n",
    "\n",
    "n_genes = 40\n",
    "\n",
    "# Make some fake gene IDs\n",
    "gene_ids = [f\"GENE_{i:03d}\" for i in range(1, n_genes + 1)]\n",
    "\n",
    "# Sample_B: base expression values\n",
    "sample_b = np.random.normal(loc=10.0, scale=4.0, size=n_genes)\n",
    "\n",
    "# Sample_C: correlated with Sample_B + some noise\n",
    "sample_c = sample_b + np.random.normal(loc=0.0, scale=2.0, size=n_genes)\n",
    "\n",
    "# GC_Content_Feature: %GC between 30 and 70\n",
    "gc_content = np.random.uniform(low=30.0, high=70.0, size=n_genes)\n",
    "\n",
    "model_ready_df = pd.DataFrame({\n",
    "    \"Gene_ID\": gene_ids,\n",
    "    \"Sample_B\": sample_b,\n",
    "    \"Sample_C\": sample_c,\n",
    "    \"GC_Content_Feature\": gc_content\n",
    "}).set_index(\"Gene_ID\")\n",
    "\n",
    "print(\"Model-ready dataset (first 5 rows):\")\n",
    "print(model_ready_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea6578",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Defining a Simple Prediction Task\n",
    "\n",
    "A machine learning model always needs two pieces of information:\n",
    "\n",
    "- **features** — the input columns the model will use  \n",
    "- **target** — the output the model should learn to predict  \n",
    "\n",
    "From our cleaned dataset, we will use:\n",
    "\n",
    "- **Sample_B**: the expression level of each gene in Sample B  \n",
    "- **GC_Content_Feature**: the GC percentage of the gene sequence  \n",
    "\n",
    "These will be the **features** the model sees.\n",
    "\n",
    "To create a **target**, we will build a simple classification task:\n",
    "\n",
    "> Predict whether a gene has **high** or **low** expression in Sample C.\n",
    "\n",
    "To define the labels, we use the **median** value of `Sample_C`:\n",
    "\n",
    "- if a gene’s `Sample_C` value is **≥ median**, we label it **1** (high expression)  \n",
    "- if it is **< median**, we label it **0** (low expression)  \n",
    "\n",
    "This turns our dataset into a clean supervised learning problem:\n",
    "\n",
    "- **Input:** expression in `Sample_B` + GC content  \n",
    "- **Output:** high vs low expression in `Sample_C`  \n",
    "\n",
    "This type of simple task is a perfect first step for showing how a model takes cleaned biological data and tries to learn a pattern from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46cb1951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_001  11.986857           66.302659\n",
      "GENE_002   9.446943           39.971689\n",
      "GENE_003  12.590754           46.415317\n",
      "GENE_004  16.092119           60.222046\n",
      "GENE_005   9.063387           39.151927\n",
      "GENE_006   9.063452           33.079196\n",
      "GENE_007  16.316851           41.590058\n",
      "GENE_008  13.069739           36.448851\n",
      "GENE_009   8.122102           67.187906\n",
      "GENE_010  12.170240           62.324815\n",
      "GENE_011   8.146329           55.336150\n",
      "GENE_012   8.137081           64.858424\n",
      "GENE_013  10.967849           62.146883\n",
      "GENE_014   2.346879           37.462802\n",
      "GENE_015   3.100329           65.702360\n",
      "GENE_016   7.750850           51.573690\n",
      "GENE_017   5.948676           62.297606\n",
      "GENE_018  11.256989           65.843652\n",
      "GENE_019   6.367904           42.720139\n",
      "GENE_020   4.350785           34.402077\n",
      "GENE_021  15.862595           39.117407\n",
      "GENE_022   9.096895           47.084312\n",
      "GENE_023  10.270113           62.720591\n",
      "GENE_024   4.301007           64.429223\n",
      "GENE_025   7.822469           30.278085\n",
      "GENE_026  10.443690           50.429892\n",
      "GENE_027   5.396026           46.696440\n",
      "GENE_028  11.502792           38.884312\n",
      "GENE_029   7.597445           34.794615\n",
      "GENE_030   8.833225           43.504607\n",
      "GENE_031   7.593174           67.716388\n",
      "GENE_032  17.409113           42.928117\n",
      "GENE_033   9.946011           50.751625\n",
      "GENE_034   5.769156           58.120758\n",
      "GENE_035  13.290180           44.545184\n",
      "GENE_036   5.116625           68.871283\n",
      "GENE_037  10.835454           68.497892\n",
      "GENE_038   2.161320           40.071292\n",
      "GENE_039   4.687256           49.889940\n",
      "GENE_040  10.787445           42.035132\n",
      "\n",
      "Target (y):\n",
      "Gene_ID\n",
      "GENE_001    1\n",
      "GENE_002    1\n",
      "GENE_003    1\n",
      "GENE_004    1\n",
      "GENE_005    0\n",
      "GENE_006    0\n",
      "GENE_007    1\n",
      "GENE_008    1\n",
      "GENE_009    1\n",
      "GENE_010    0\n",
      "GENE_011    1\n",
      "GENE_012    0\n",
      "GENE_013    1\n",
      "GENE_014    0\n",
      "GENE_015    0\n",
      "GENE_016    1\n",
      "GENE_017    0\n",
      "GENE_018    1\n",
      "GENE_019    0\n",
      "GENE_020    0\n",
      "GENE_021    1\n",
      "GENE_022    1\n",
      "GENE_023    0\n",
      "GENE_024    0\n",
      "GENE_025    1\n",
      "GENE_026    1\n",
      "GENE_027    0\n",
      "GENE_028    1\n",
      "GENE_029    0\n",
      "GENE_030    0\n",
      "GENE_031    0\n",
      "GENE_032    1\n",
      "GENE_033    1\n",
      "GENE_034    1\n",
      "GENE_035    0\n",
      "GENE_036    0\n",
      "GENE_037    1\n",
      "GENE_038    0\n",
      "GENE_039    0\n",
      "GENE_040    0\n",
      "Name: Sample_C, dtype: int64\n",
      "\n",
      "Median of Sample_C: 8.684868354172306\n"
     ]
    }
   ],
   "source": [
    "# Features: what the model will see\n",
    "X = model_ready_df[[\"Sample_B\", \"GC_Content_Feature\"]]\n",
    "\n",
    "# Target: high vs low expression in Sample_C\n",
    "median_sample_c = model_ready_df[\"Sample_C\"].median()\n",
    "y = (model_ready_df[\"Sample_C\"] >= median_sample_c).astype(int)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X)\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y)\n",
    "print(f\"\\nMedian of Sample_C: {median_sample_c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abe100",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Splitting the Data: Training vs Testing\n",
    "\n",
    "Now that we have defined our features (`X`) and target labels (`y`), the next step is to split the dataset into:\n",
    "\n",
    "- **training data** — what the model learns from  \n",
    "- **test data** — what we hold back to evaluate the model on unseen examples  \n",
    "\n",
    "This is one of the core habits of machine learning:  \n",
    "the model must be judged on data it did **not** see during training.\n",
    "\n",
    "Because we now have a larger synthetic dataset (40 genes), we can safely split it 50/50 just for demonstration. In a real project, you might use 70/30 or 80/20 splits.\n",
    "\n",
    "The code below creates:\n",
    "\n",
    "- `X_train`, `y_train` — used to train the model  \n",
    "- `X_test`, `y_test` — used later to evaluate accuracy\n",
    "\n",
    "We also set a fixed `random_state` so the split is reproducible every time you run the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5f481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features:\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_006   9.063452           33.079196\n",
      "GENE_012   8.137081           64.858424\n",
      "GENE_002   9.446943           39.971689\n",
      "GENE_030   8.833225           43.504607\n",
      "GENE_022   9.096895           47.084312\n",
      "GENE_003  12.590754           46.415317\n",
      "GENE_031   7.593174           67.716388\n",
      "GENE_037  10.835454           68.497892\n",
      "GENE_004  16.092119           60.222046\n",
      "GENE_036   5.116625           68.871283\n",
      "GENE_024   4.301007           64.429223\n",
      "GENE_033   9.946011           50.751625\n",
      "GENE_011   8.146329           55.336150\n",
      "GENE_023  10.270113           62.720591\n",
      "GENE_019   6.367904           42.720139\n",
      "GENE_021  15.862595           39.117407\n",
      "GENE_008  13.069739           36.448851\n",
      "GENE_015   3.100329           65.702360\n",
      "GENE_029   7.597445           34.794615\n",
      "GENE_039   4.687256           49.889940\n",
      "\n",
      "Training labels:\n",
      "Gene_ID\n",
      "GENE_006    0\n",
      "GENE_012    0\n",
      "GENE_002    1\n",
      "GENE_030    0\n",
      "GENE_022    1\n",
      "GENE_003    1\n",
      "GENE_031    0\n",
      "GENE_037    1\n",
      "GENE_004    1\n",
      "GENE_036    0\n",
      "GENE_024    0\n",
      "GENE_033    1\n",
      "GENE_011    1\n",
      "GENE_023    0\n",
      "GENE_019    0\n",
      "GENE_021    1\n",
      "GENE_008    1\n",
      "GENE_015    0\n",
      "GENE_029    0\n",
      "GENE_039    0\n",
      "Name: Sample_C, dtype: int64\n",
      "\n",
      "Test features:\n",
      "           Sample_B  GC_Content_Feature\n",
      "Gene_ID                                \n",
      "GENE_020   4.350785           34.402077\n",
      "GENE_017   5.948676           62.297606\n",
      "GENE_016   7.750850           51.573690\n",
      "GENE_027   5.396026           46.696440\n",
      "GENE_005   9.063387           39.151927\n",
      "GENE_013  10.967849           62.146883\n",
      "GENE_038   2.161320           40.071292\n",
      "GENE_028  11.502792           38.884312\n",
      "GENE_040  10.787445           42.035132\n",
      "GENE_007  16.316851           41.590058\n",
      "GENE_026  10.443690           50.429892\n",
      "GENE_010  12.170240           62.324815\n",
      "GENE_014   2.346879           37.462802\n",
      "GENE_032  17.409113           42.928117\n",
      "GENE_035  13.290180           44.545184\n",
      "GENE_009   8.122102           67.187906\n",
      "GENE_018  11.256989           65.843652\n",
      "GENE_025   7.822469           30.278085\n",
      "GENE_001  11.986857           66.302659\n",
      "GENE_034   5.769156           58.120758\n",
      "\n",
      "Test labels:\n",
      "Gene_ID\n",
      "GENE_020    0\n",
      "GENE_017    0\n",
      "GENE_016    1\n",
      "GENE_027    0\n",
      "GENE_005    0\n",
      "GENE_013    1\n",
      "GENE_038    0\n",
      "GENE_028    1\n",
      "GENE_040    0\n",
      "GENE_007    1\n",
      "GENE_026    1\n",
      "GENE_010    0\n",
      "GENE_014    0\n",
      "GENE_032    1\n",
      "GENE_035    0\n",
      "GENE_009    1\n",
      "GENE_018    1\n",
      "GENE_025    1\n",
      "GENE_001    1\n",
      "GENE_034    1\n",
      "Name: Sample_C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,   # half of the genes for testing, just for demonstration\n",
    "    random_state=42  # fixed seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Training features:\")\n",
    "print(X_train)\n",
    "print(\"\\nTraining labels:\")\n",
    "print(y_train)\n",
    "print(\"\\nTest features:\")\n",
    "print(X_test)\n",
    "print(\"\\nTest labels:\")\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c3152",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Training a Simple Machine Learning Model\n",
    "\n",
    "With the training and test sets prepared, we can now build our first machine learning model.  \n",
    "To keep things intuitive, we’ll use a **RandomForestClassifier**, a model that works well with small datasets and gives us interpretable results.\n",
    "\n",
    "A Random Forest is simply a collection of decision trees:\n",
    "\n",
    "- each tree learns a slightly different pattern  \n",
    "- their results are combined (a “vote”)  \n",
    "- the final prediction is usually more stable than any single tree  \n",
    "\n",
    "For our TechBio example, this model is perfect because:\n",
    "\n",
    "- it handles non-linear patterns  \n",
    "- it does not require feature scaling  \n",
    "- it gives **feature importance scores**, which help us understand what the model is focusing on  \n",
    "\n",
    "In the code below, we:\n",
    "\n",
    "1. create the model  \n",
    "2. set the number of trees (we’ll use 50 for a stable demo)  \n",
    "3. train (“fit”) the model on the training data  \n",
    "\n",
    "After this step, the model has learned a relationship between:\n",
    "\n",
    "- the inputs (`Sample_B` and `GC_Content_Feature`)  \n",
    "- the output (high vs low expression in `Sample_C`)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f41a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,      # number of trees in the forest\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train (fit) the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a73fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Making Predictions and Evaluating the Model\n",
    "\n",
    "Now that our model has been trained on the training set, it’s time to see how well it performs on **new, unseen data**.  \n",
    "This is the whole purpose of machine learning evaluation: we want to check whether the model learned a real pattern, not just memorized the training examples.\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "1. **Use the model to predict** the labels for the test set (`X_test`)\n",
    "2. **Compare** the predictions to the true labels (`y_test`)\n",
    "3. **Compute the accuracy**, which is the fraction of correct predictions\n",
    "\n",
    "With synthetic biological data like ours, we don’t expect perfect accuracy.  \n",
    "A realistic model should make some mistakes — that’s normal. The important part is understanding the workflow:\n",
    "\n",
    "> Train → Predict → Evaluate\n",
    "\n",
    "This mirrors the same cycle used in real TechBio pipelines, where the goal is not perfection on day one, but **gradual learning across multiple iterations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c807e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels:      [np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
      "Predicted labels: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
      "\n",
      "Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"True labels:     \", list(y_test.values))\n",
    "print(\"Predicted labels:\", list(y_pred))\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec986f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Interpreting the Model: Feature Importance\n",
    "\n",
    "Accuracy tells us *how well* the model performs, but it doesn’t tell us **why** the model makes its decisions.  \n",
    "To open that “black box” a little, we can look at the **feature importances** calculated by the Random Forest.\n",
    "\n",
    "A Random Forest is made of many decision trees. Each tree splits the data based on the features that help it separate high-expression vs low-expression genes.  \n",
    "When a feature is consistently useful across many trees, it gets a higher importance score.\n",
    "\n",
    "In this notebook, we have two features:\n",
    "\n",
    "- `Sample_B` — the expression level in Sample B  \n",
    "- `GC_Content_Feature` — the GC percentage of the gene sequence  \n",
    "\n",
    "By looking at their importance scores, we can understand which signal the model relied on more to make predictions.\n",
    "\n",
    "This kind of interpretation is essential in TechBio workflows because it helps you connect **model behavior** back to **biological meaning**.  \n",
    "Even with synthetic data, the pattern of importance shows how models prioritize different types of information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a9fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "              Feature  Importance\n",
      "0            Sample_B    0.690982\n",
      "1  GC_Content_Feature    0.309018\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance values\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6c6e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Bringing It All Together\n",
    "\n",
    "With this notebook, we completed the full path from **clean data** to a **working predictive model**.  \n",
    "The model is simple, the dataset is synthetic, and the accuracy is not the main goal.  \n",
    "What matters is the structure of the workflow:\n",
    "\n",
    "1. Start with model-ready biological data  \n",
    "2. Define features and target labels  \n",
    "3. Split the data into training and testing sets  \n",
    "4. Train a basic machine learning model  \n",
    "5. Evaluate its predictions on unseen data  \n",
    "6. Interpret the model to understand which features mattered  \n",
    "\n",
    "This mirrors the real TechBio cycle:\n",
    "\n",
    "> Biology → Data → Cleaning → **Model** → Validation → Better Biology\n",
    "\n",
    "It’s important to emphasize that the purpose of this notebook is **not** to teach machine learning in depth.  \n",
    "The goal is simply to make the modeling step of the TechBio workflow concrete, so readers understand how structured data turns into a first predictive signal.  \n",
    "Everything here is intentionally simple so the focus stays on the *concepts* described in the book, not on ML theory.\n",
    "\n",
    "In real research or startup work, this loop repeats many times.  \n",
    "Each round improves the dataset, the features, and the accuracy of the model.  \n",
    "This is how a simple experimental table gradually becomes the engine of a TechBio platform.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Your Turn: Try Small, Real Experiments\n",
    "\n",
    "To make the ideas in this notebook “stick,” here are a few hands-on changes you can try.  \n",
    "Each one teaches an important intuition about how modeling fits into the TechBio loop.\n",
    "\n",
    "### **1. Change the Target Definition**\n",
    "Instead of classifying high vs low expression based on the median of `Sample_C`, try:\n",
    "\n",
    "- using the median of **Sample_B**  \n",
    "- or defining “high expression” as the top 25%  \n",
    "- or predicting **whether Sample_C is greater than Sample_B**\n",
    "\n",
    "This shows how different biological assumptions change the modeling problem.\n",
    "\n",
    "\n",
    "### **2. Add or Remove Features**\n",
    "Try training the model with:\n",
    "\n",
    "- **only** `Sample_B`  \n",
    "- **only** `GC_Content_Feature`  \n",
    "- or by adding a new synthetic feature like noise or a random column  \n",
    "\n",
    "Watch how accuracy and feature importance change.\n",
    "\n",
    "\n",
    "### **3. Change the Model Type**\n",
    "Swap the Random Forest for another simple algorithm:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
